# -*- coding: utf-8 -*-
"""Bejing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X9CeRrJeHjCrig8KxSiPWRD-KuZjDwn4
"""

import pandas as pd
import glob
import os

# Define the path to the folder containing the CSV files
folder_path = '/content/'

# Use glob to find all CSV files in the folder
csv_files = glob.glob(os.path.join(folder_path, '*.csv'))

# Read and concatenate all CSV files
all_dfs = []

for file in csv_files:
    print(f"Reading {file}...")
    df = pd.read_csv(file)
    df['source_file'] = os.path.basename(file)  # Optional: keep track of source
    all_dfs.append(df)

# Concatenate into a single DataFrame
merged_df = pd.concat(all_dfs, ignore_index=True)

# Display basic info
print("All files merged successfully.")
print("Combined DataFrame shape:", merged_df.shape)
print(merged_df.head())

# Check how many unique stations are present
print("Unique stations:", merged_df['station'].nunique())
print("Stations:", merged_df['station'].unique())

# Group by station to check data volume
print(merged_df['station'].value_counts())

# Strip spaces and lower case for uniformity
merged_df['station'] = merged_df['station'].str.strip().str.lower()

missing_values = merged_df.isnull().sum()
print("Missing values per column:\n", missing_values)

# Example: Drop rows with excessive missing pollution data
merged_df_cleaned = merged_df.dropna(subset=['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3'])

merged_df['datetime'] = pd.to_datetime(merged_df[['year', 'month', 'day', 'hour']])
merged_df.set_index('datetime', inplace=True)

# General statistics
print("Statistical summary:\n", merged_df.describe())

import matplotlib.pyplot as plt

# Average PM2.5 per month across all stations
monthly_pm25 = merged_df['PM2.5'].resample('M').mean()

plt.figure(figsize=(14, 5))
monthly_pm25.plot(title='Monthly Average PM2.5 Levels (All Stations)', ylabel='PM2.5 (µg/m³)', xlabel='Date')
plt.grid(True)
plt.tight_layout()
plt.show()

# Reset index to ensure seaborn handles it correctly
plot_df = merged_df.reset_index()

plt.figure(figsize=(14, 6))
sns.boxplot(x='station', y='PM2.5', data=plot_df)
plt.title('PM2.5 Distribution by Station')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Numeric correlation matrix
numeric_cols = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']
corr = merged_df[numeric_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)
plt.title('Correlation Heatmap of Pollutants and Weather Variables')
plt.tight_layout()
plt.show()

# Reset index before plotting
plot_df = merged_df.reset_index()

plt.figure(figsize=(8, 5))
sns.scatterplot(data=plot_df, x='TEMP', y='PM2.5', alpha=0.3)
plt.title('PM2.5 vs Temperature')
plt.tight_layout()
plt.show()

# Calculate daily average PM2.5 for all stations
daily_pm25 = merged_df.groupby(merged_df.index.date)['PM2.5'].mean()

# Plot the trend
plt.figure(figsize=(15, 5))
daily_pm25.plot()
plt.title('Daily Average PM2.5 Over Time (All Stations)')
plt.xlabel('Date')
plt.ylabel('PM2.5 Concentration (µg/m³)')
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno

# Summary statistics
print(merged_df.describe())

# Visualize missing values
plt.figure(figsize=(10, 4))
msno.matrix(merged_df)
plt.title("Missing Values Matrix")
plt.show()

# Correlation heatmap (excluding non-numeric)
plt.figure(figsize=(12, 8))
corr = merged_df.select_dtypes(include='number').corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer

# Selecting features and target
features = ['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']
target = 'PM2.5'

# Filter out rows where target is missing
model_df = merged_df[features + [target]].dropna(subset=[target])

# Handle missing values in features
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(model_df[features])
y = model_df[target]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# Evaluation
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))